data = DataFrame(CSV.File("tacke10.csv"))#ubacujem datu iz drugog fajla
c =  cor(data.x, data.y)#korelacija podataka
println("Koeficijent korelacije je: $c")
if c>0.9
   println("Postoji veoma jaka veza izmedju podataka")
elseif c>0.7
   println("Postoji jaka veza izmedju podataka ")
elseif c>0.5
   println("Postoji umerena veza izmedju podataka ")
else
   println("Veza izmedju podataka nije dovoljno jaka")
end
dataTrain, dataTest = TrainTestSplit(data,.80)#split na trening test  80 posto ide u train

myInputPlot = scatter(dataTrain.x,dataTrain.y, title = "Tacke, pre linearne regresije", ylabel = "Y values", xlabel = "X value")#kreira grafik
scatter!(myInputPlot, dataTest.x, dataTest.y)#docrtava na grafik
fm = @formula(y ~ x)
linearRegressor = lm(fm, dataTrain)

dataPredictedTrain = predict(linearRegressor, dataTrain)
dataPredictedTest = predict(linearRegressor, dataTest)
# Ispis podataka sa testiranja
for i in 1:length(dataPredictedTest)
   println("(X$i, Y$i) = ($(dataTest.x[i]), $(dataTest.y[i])) Predicted: Y$i $(dataPredictedTest[i])")
end
# Grafikon podataka sa testiranja
myOutputPlot = scatter(dataTrain.x, dataTrain.y, title = "Tacke, tacke posle linearne regresije", ylabel = "Y values", xlabel = "X value", legend=:bottomright)
scatter!(myOutputPlot, dataTest.x, dataTest.y)
scatter!(myOutputPlot, dataTest.x, dataPredictedTest)
scatter(myOutputPlot)
rSquared = r2(linearRegressor)
println("Vrednost r squared iznosi $rSquared")
if (rSquared>0.9)
   println("Ovaj model je jako dobar za predvidjanje")
elseif (rSquared>0.7)
   println("Ovaj model je veoma dobar za predvidjanje")
elseif (rSquared>0.5)
   println("Ovaj model je relativno dobar za predvidjanje")
else 
   println("Ovaj model nije dobar za predvidjanje")
end

errorsTrain = dataTrain.y-dataPredictedTrain
println()
println("Spisak svih gresaka pri obuci je: $(round.(errorsTrain; digits = 3))")
# Racunanje proseka greske
absMeanErrorTrain = mean(abs.(errorsTrain))
# Racunanje prosecne relativne greske u procentima MAPE
mapeTrain = mean(abs.(errorsTrain./dataTrain.y))
# Racunanje kvadarata gresaka za svaku vrednost posebno
errorTrainSquared = errorsTrain.*errorsTrain
# Racunanje MSE i RMSE (Root Mean Square Error)
mseTrain = mean(errorTrainSquared)
rmseTrain = sqrt(mean(errorTrainSquared))

println("Prosecna absolutna greska pri obuci je: $absMeanErrorTrain")
println("Prosecna relativna greska pri obuci je: $mapeTrain")
println("Prosek kvadarata greske pri obuci je: $mseTrain")
println("Koren proseka kvadarata greske pri obuci je: $rmseTrain")

# Racunanje gresaka za test skup
# Racunanje gresaka za svaku vrednost posebno
errorsTest = dataTest.y-dataPredictedTest
println()
println("Spisak svih gresaka pri testiranju je: $(round.(errorsTest; digits = 3))")
# Racunanje proseka greske
absMeanErrorTest = mean(abs.(errorsTest))
# Racunanje prosecne relativne greske u procentima MAPE
mapeTest = mean(abs.(errorsTest./dataTest.y))
# Racunanje kvadarata gresaka za svaku vrednost posebno
errorTestSquared = errorsTest.*errorsTest
# Racunanje MSE i RMSE (Root Mean Square Error)
mseTest = mean(errorTestSquared)
rmseTest = sqrt(mean(errorTestSquared))

println("Prosecna absolutna greska pri testiranju je: $absMeanErrorTest")
println("Prosecna relativna greska pri testiranju je: $mapeTest")
println("Prosek kvadarata greske pri testiranju je: $mseTest")
println("Koren proseka kvadarata greske pri testiranju je: $rmseTest")

# Provera da li je sistem pogodan za testiranje
if (rmseTrain<rmseTest)
   println("Sistem je dobro istreniran")
else
   println("Sistem nije dobro istreniran")
end
#########
display(describe(df)) #za ceo
display(countmap(df[!, :NazivPromenljive]))#za 1 kolonu-df smo napravili ranije  sa datafremae\
select!(df, Not(:NazivKolone)) #ukloni red npr izbacimo neki podatak ako na ne treba
u dropmissing!(df, [:NazivKolone])#izbacuju kolone gde podaci neke kolone  nedostaju
df[ismissing.(df[!, :Stanje]), :Stanje] .= mode(skipmissing(df[!, :Stanje]))#popunjavamo prazna polja najcescim
df[ismissing.(df[!, :Kilometraza]), :Kilometraza] .= trunc(Int64,mean(skipmissing(df[!, :Kilometraza])))#numericke vrednosti prosekom
display(describe(df))#opet ga display samo punog
#Nacrtamo scatter plot za svaku  promenljivu kako bismo identifikovali podatke koji jako odskacu kao i korelaciju
#trazimo koji strca da bi ih izbacili posle
plotappl = scatter(df.Godiste, df.Cena, title = "Scatter Godiste - Cena", ylabel = "Cena", xlabel = "Godiste", legend = true)  
display(plotappl)
savefig(plotappl, "godistescatter.html")#tako za svaku
#izbacimo sve motore kojima je godiste iznad 2021 i ispod 1900
filter!(row ->row.Godiste <= 2021 && row.Godiste > 1900, df)

#Ako pogledamo grafike za KW i KS vidimo da su slicni sto ukazuje na potencijalnu multikolinearnost
covKwKs = cov(df.kW, df.KS)

#Ukoliko detektujemo multikolinearnost izbacimo jednu od promenljivih iz modela
if(covKwKs > 0.6)
    select!(df, Not(:kW))
end
#logicka regresija
isto do lma
logisticRegressor = glm(fm, dataTrain, Binomial(), ProbitLink()) # Bernoulli(), Binomial(), Gamma(), Normal() ili Poisson() 
#Najčešće kombinacije familije i linka su Bernoulli() i LogitLink(), Binomial() i
#LogitLink(), Gamma() i InverseLink(), Normal() i InverseLink(), Poisson() i LogLink()

#odavde krece
data = DataFrame(CSV.File("tacke1000a.csv"))
dataTrain, dataTest = TrainTestSplit(data,.80)
myInputPlot = scatter(dataTrain.x,dataTrain.y, title = "Tacke, pre logisticke regresije", ylabel = "Y values", xlabel = "X value")
scatter!(myInputPlot, dataTest.x, dataTest.y)
fm = @formula(boja ~ x+y)
logisticRegressor = glm(fm, dataTrain, Binomial(), ProbitLink()) 	
dataPredictedTest = predict(logisticRegressor, dataTest)
println("Predvidjeni podaci: $(round.(dataPredictedTest; digits = 2))")

# Racunanje matrice
dataPredictedTestClass = repeat(0:0, length(dataPredictedTest))
for i in 1:length(dataPredictedTest)
    if (dataPredictedTest[i] <0.5)
        dataPredictedTestClass[i] = 0
    else
        dataPredictedTestClass[i] = 1
    end
end
println("Predvidjene boje: $dataPredictedTestClass)")
println("Boje: $(dataTest.boja))")

FPTest = 0 # false positives
FNTest = 0 # false negatives
TPTest = 0 # true positives
TNTest = 0 # true negatives
for i in 1:length(dataPredictedTestClass)
    if dataTest.boja[i] == 0 && dataPredictedTestClass[i] == 0
        global TNTest += 1;
    elseif dataTest.boja[i] == 0 && dataPredictedTestClass[i] == 1
        global FPTest +=1
    elseif dataTest.boja[i] == 1 && dataPredictedTestClass[i] == 0
        global FNTest +=1
    elseif dataTest.boja[i] == 1 && dataPredictedTestClass[i] == 1
        global TPTest +=1
    end
end

# Umesto gornje petlje moze se koristiti i:
# confusion_matrix = MLBase.roc(dataTest.boja, dataPredictedTestClass)

# accuracy (preciznost) = (TP+TN)/(TP+TN+FP+FN) = (TP+TN)/(P+N)
accuracyTest = (TPTest+TNTest)/(TPTest+TNTest+FPTest+FNTest)

# sensitivity (osetljivost, True positive rates) = TP/(TP+FN) = TP/P
sensitivityTest = TPTest/(TPTest+FNTest)

# specificity (specifičnost, True negative rates) = TN/(TN+FP) = TN/N
specificityTest = TNTest/(TNTest+FPTest)

println("TP = $TPTest, FP = $FPTest, TN =$TNTest, FN = $FNTest")
println("Accuracy za test skup je $accuracyTest")
println("Sensitivity za test skup je $sensitivityTest")
println("Specificity za test skup je $specificityTest")

rocTest = ROC.roc(dataPredictedTest, dataTest.boja, true)
aucTest = AUC(rocTest)
println("Povrsina ispod krive u procentima je: $aucTest")

if (aucTest>0.9)
    println("Klasifikator je jako dobar")
elseif (aucTest>0.8)
    println("Klasifikator je veoma dobar")
elseif (aucTest>0.7)
    println("Klasifikator je dosta dobar")
elseif (aucTest>0.5)
    println("Klasifikator je relativno dobar")
else
    println("Klasifikator je los")
end
    
plot(rocTest, label="ROC curve")#graf vez tacki